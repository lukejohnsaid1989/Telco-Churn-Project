---
title: "Telco Churn"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

In this Project we shall predict customer churn for a Telecommunications company "Telco". All credit for the dataset goes to Kaggle User "BlastChar" and can be accessed here: https://www.kaggle.com/blastchar/telco-customer-churn

Let's start off by loading our dataset and the required libraries.

```{r}

#Let's import the dataset

library(readr)
WA_F <- read_csv("https://raw.githubusercontent.com/lukejohnsaid1989/Telco-Churn-Project/master/Telco%20Customer%20ChurnWA_Fn-UseC_-Telco-Customer-Churn.csv")

mydata <-WA_F

#Let's load the Libraries
library(data.table)
library(dplyr)
library(ggplot2)
library(caret)
library(class)

```
**Sections**:

*1. Introduction and Dataset exploration*

*2. Variable Analysis and Data Exploration / Cleanup*

*3. Model Building*

*4. Prediction and Accuracy Evaluation*

*5. Conclusions and Future Work*

**SECTION 1: INTRODUCTION**

We will create a Logistic Regression model to predict customer churn.

We will be analysing variable by variable and modifying the data in a way that can be easily interpreted by a Logistic Regression model. Variables with text data will be split into "N" columns where "N" is the number of levels of the variable. These columns will be populated with 1s and 0s depending on the level of the original Variable column. Variables with numeric data can be fit into the regression model as they are.

All variables will then be standardized. This will give the variables zero-mean and unit-variance. This is done to mitigate the issue created by different ranges shown by different variables.

Summing this up, we will:

* Load our data
* Take a look at each variable to: 
    * Check for NAs (and replace if necessary) 
    * Manipulate Data to make it interpretable by a regression model
* Select which features we will include into our regression model
* Standardize all our data
* Split our data into Train and Test sets
* Fit our Logistic Regression Model
* Use the Train set to predict our Test Set
* Evaluate the accuray of our model

*Dataset Exploration*
Let us now take a look at our dataset.

```{r}
#Let's take a look at our dataset
head(mydata)
```

Let's check for NAs. As per the below output, we have 11 NAs.

```{r}

#Check for NAs
sum(is.na(mydata))
#We have 11 Na's
```

Let us take a look at our **output Variable**; which is the column "Churn". Let's check for NAs, and plot.  There are much less people who churned than who didn't. As per the below output, we have no NAs.

```{r}
#Let's look at our output 

base::table(mydata$Churn)
sum(is.na(mydata$Churn))

ggplot(mydata, aes(mydata$Churn)) + geom_bar(fill = "#FF6666") + theme_classic() + xlab("Churn")

```
Since we know that we will be using Logistic Regression - we need to switch our output Variable to 0s and 1s. The value of 1 represents customer churn.

I added a new column "ChurnLog" which contains binary data for Churn.

```{r}
mydata$ChurnLog = 0
mydata$ChurnLog[mydata$Churn == "Yes"] = 1
mydata$ChurnLog[mydata$Churn == "No"] = 0

head(mydata)
```

Let's take a look at our column names. Creating a vector with the names of columns is useful if you want to call upon it to check the exact names of the columns.
```{r}
ColVec <- colnames(mydata)
ColVec
```

**SECTION 2: VARIABLE ANALYSIS AND DATA EXPLORATION / CLEANUP**

->>> Variable Analysis

      ///GENDER///

First we check our levels. We have two, "Male" and "Female". Then we check for NAs. We have no NAs.

```{r}
base::table(mydata$gender)
sum(is.na(mydata$gender))
```

I created a dataframe using Dummy Variables. This dataframe contains two columns with binary values representing the Gender variable from mydata. This will be used to develop the logistic regression model.

```{r}
Genderframe <-as.data.frame(mydata$gender)
dmy <- dummyVars(" ~ .", data = Genderframe)
Genderframe2 <- data.frame(predict(dmy, newdata = Genderframe))
head(Genderframe2)

```

->>> Variable Analysis

      ///PARTNER///

First we check our levels. We have two, "Yes" and "No". Then we check for NAs. I added a new column "PartnerLog" which contains binary data for Partner. As per the output - we have no NAs.

```{r}
mydata$PartnerLog = 0
sum(is.na(mydata$Partner))

mydata$PartnerLog[mydata$Partner == "Yes"] = 1 
mydata$PartnerLog[mydata$Partner == "No"] = 0 
head(mydata)
```

->>> Variable Analysis

      ///SENIOR CITIZEN///

Let's take a look at Senior Citizen. It is already in 1s and 0s, so we need not modify it. Also we have no NAs.
```{r}
base::table(mydata$SeniorCitizen)
sum(is.na(mydata$SeniorCitizen))
```

>>> Variable Analysis

      ///DEPENDENTS///


Now let us take a look at dependents. As per the code ouput below, we have no NAs. We will create another column with Binary Data, as we did for Gender.

```{r}

base::table(mydata$Dependents)
sum(is.na(mydata$Dependents))

mydata$DependentsLog = 0
mydata$DependentsLog[mydata$Dependents == "Yes"] = 1
mydata$DependentsLog[mydata$Dependents == "No"] = 0
tail(mydata)
```

>>> Variable Analysis

      ///TENURE///

Let's take a look at tenure. As per the code output, we have no NAs. The distribution is not Normal. When looking at the violin plot it is evident that there is a higher probability that people with lower tenure will Churn.

```{r}
sum(is.na(mydata$tenure))

```

```{r}
ggplot(mydata, aes(mydata$tenure)) + geom_histogram(binwidth = 2, fill = "#E69F00") + theme_classic() +xlab("Tenure") +  theme_classic()
```

```{r}

ggplot(mydata, aes(mydata$Churn, mydata$tenure)) + geom_violin(fill = "#FF6677") + xlab("Churn") +ylab("Tenure") + theme_classic()
```

Now Lets create a dataframe to split the tenure data into:

1. Values with zero value
2. Values betwen Between 1 and 20
3. Values between Between 21 and 40
4. Values between Between 41 and 60
5. Values over 61

```{r}

TenureFrame <- as.data.frame(mydata$tenure)
x = 1
while (x<=nrow(TenureFrame)){
  if ((TenureFrame$`mydata$tenure`[x] > 0) & (TenureFrame$`mydata$tenure`[x] <= 20)) 
        {TenureFrame$`mydata$tenure`[x] = "Between 1 and 20"}
  else if ((TenureFrame$`mydata$tenure`[x] > 20) & (TenureFrame$`mydata$tenure`[x] <= 40)) 
        {TenureFrame$`mydata$tenure`[x] = "Between 21 and 40"}
  else if ((TenureFrame$`mydata$tenure`[x] > 40) & (TenureFrame$`mydata$tenure`[x] <= 60)) 
        {TenureFrame$`mydata$tenure`[x] = "Between 41 and 60"}
  else if (TenureFrame$`mydata$tenure`[x] > 60) 
  {TenureFrame$`mydata$tenure`[x] = "Over 61"}
  x = x + 1
}
```

```{r}

base::table(TenureFrame$`mydata$tenure`)
```

Let's plot out Tenure data again.

```{r}
ggplot(mydata, aes(TenureFrame$`mydata$tenure`)) + geom_bar(fill = "#56B4E9") + theme_classic() + xlab("Tenure")

```

Now let's use Dummy Vars to create a dataframe with columns containing binary data representing the tenure periods defined. Loading up this data frame, we can see that we have the 5 columns we defined.

```{r}
# let's create dummy var!

dmy <- dummyVars(" ~ .", data = TenureFrame)
TenureFrame2 <- data.frame(predict(dmy, newdata = TenureFrame))
head(TenureFrame2)

```

>>> Variable Analysis

      ///ANALYSIS OF SERVICES AVAILABLE///


The following Variables are all related to the Phone and Internet services:

      Phone Service
      MultipleLines
      InternetService
      OnlineSecurity
      OnlineBackup
      DeviceProtection
      TechSupport
      StreamingTV
      SreamingMovies

We will first check for NAs in each variable. Then we will take a look at the levels of each Variable. No NAs as per the below output. Also, it can be noted that we have a lot of duplicate information. In each service related to Internet service (such as Online backup and Streaming Movies), we have a level specifying "No Internet Service". This is the same amount (1526) showing "No" in the "Internet Service" Variable.

 
```{r}
base::table(mydata$PhoneService)
sum(is.na(mydata$PhoneService))
base::table(mydata$MultipleLines)
sum(is.na(mydata$MultipleLines))
base::table(mydata$InternetService)
sum(is.na(mydata$InternetService))
base::table(mydata$OnlineSecurity)
sum(is.na(mydata$OnlineSecurity))
base::table(mydata$OnlineBackup)
sum(is.na(mydata$OnlineBackup))
base::table(mydata$DeviceProtection)
sum(is.na(mydata$DeviceProtection))
base::table(mydata$TechSupport)
sum(is.na(mydata$TechSupport))
base::table(mydata$StreamingTV)
sum(is.na(mydata$StreamingTV))
base::table(mydata$StreamingMovies)
sum(is.na(mydata$StreamingMovies))

```

We will now use Dummy Variables to create a dataframe with binary data on each of these Variables. 

!We must then remove colums containing duplicate data! 

```{r}
ServiceFrame <- cbind.data.frame(mydata$PhoneService, mydata$MultipleLines, mydata$InternetService, mydata$OnlineSecurity, mydata$OnlineBackup, mydata$DeviceProtection, mydata$TechSupport, mydata$StreamingTV, mydata$StreamingMovies)
ncol(ServiceFrame)
```
```{r}
dmy <- dummyVars(" ~ .", data = ServiceFrame)
ServiceFrame2 <- data.frame(predict(dmy, newdata = ServiceFrame))
head(ServiceFrame2 )

```

It can be observed that there are a lot of columns with duplicate information. The following are examples:

X.mydata.PhoneService.No
X.mydata.MultipleLines.No.phone.service
We will remove the redunant columns:    

```{r}
ServiceFrame2ColVec <-colnames(ServiceFrame2)
ServiceFrame2ColVec

ServiceFrame2 <-subset(ServiceFrame2, select =-X.mydata.MultipleLines.No.phone.service)
ServiceFrame2 <-subset(ServiceFrame2, select =-X.mydata.OnlineSecurity.No.internet.service)
ServiceFrame2 <-subset(ServiceFrame2, select =-X.mydata.TechSupport.No.internet.service)
ServiceFrame2 <-subset(ServiceFrame2, select =-X.mydata.StreamingTV.No.internet.service)
ServiceFrame2 <-subset(ServiceFrame2, select =-X.mydata.StreamingMovies.No.internet.service)
ServiceFrame2 <-subset(ServiceFrame2, select =-X.mydata.OnlineBackup.No.internet.service)
ServiceFrame2 <-subset(ServiceFrame2, select =-X.mydata.DeviceProtection.No.internet.service)

head(ServiceFrame2)
ncol(ServiceFrame2)

```

>>> Variable Analysis

      ///CONTRACT///


Let's take a look at contract. We have no NAs, and we have 3 levels. Again, lets use Dummy Variables to creata a dataframe with binary data.

```{r}
base::table(mydata$Contract)
sum(is.na(mydata$Contract))
ContractFrame <- cbind.data.frame(mydata$Contract)
dmy <- dummyVars(" ~ .", data = ContractFrame)
ContractFrame2 <- data.frame(predict(dmy, newdata = ContractFrame))
head(ContractFrame2)
```

>>> Variable Analysis

      ///PAPERLESS BILLING///
We have no NAs in this variable. Let's create a column with binary data.

```{r}

base::table(mydata$PaperlessBilling)
sum(is.na(mydata$PaperlessBilling))

mydata$PaperlessBillingLog[mydata$PaperlessBilling == "Yes"] = 1
mydata$PaperlessBillingLog[mydata$PaperlessBilling == "No"] = 0

head(mydata)

```

>>> Variable Analysis

      ///PAYMENT METHOD///

Let's take a look at payment method. We have no NAs, and 4 levels. Let's create another dataframe with binary values.

```{r}

base::table(mydata$PaymentMethod)
sum(is.na(mydata$PaymentMethod))

PaymentFrame <- as.data.frame(mydata$PaymentMethod)

dmy <- dummyVars(" ~ .", data = PaymentFrame)
PaymentFrame2 <- data.frame(predict(dmy, newdata = PaymentFrame))
head(PaymentFrame2)

```

>>> Variable Analysis

      ///MONTHLY CHARGES///


Let's look at monthly charges. We have no NAs. Talking a look at the Violin graph, it appears that those with high monthly charges are more likely to churn.

```{r}
sum(is.na(mydata$MonthlyCharges))

```

```{r}
ggplot(mydata, aes(mydata$MonthlyCharges)) + geom_histogram(binwidth = 2, fill = "#E69F00") + xlab("Monthly Charges")
```

```{r}

ggplot(mydata, aes(mydata$Churn, mydata$MonthlyCharges)) + geom_violin(fill = "#FF6677") + xlab("Churn") +ylab("Monthly Charges") + theme_classic()
```

>>> Variable Analysis

      ///TOTAL CHARGES///

Let's take a look at total charges. We have 11 Nas.

```{r}
sum(is.na(mydata$TotalCharges))

```

-> *VALUE IMPUTATION*

We need to replace the 11 Na values that we have in the "Total Charges" Column.

Let's take a look at the relationship between Monthly Charges and Total Charges. Let's create a column to Analyse this relationship. We will divide the Total Charges by the tenure and verify if it is similar to the Monthly Charges. Indeed they are very similar. In this regard, for the values which are missing from "Total Charges" we can simply multiply the monthly charges with the tenure.

```{r}
mydata$TotalChargesDivTenure <- (mydata$TotalCharges/mydata$tenure)

test <-cbind.data.frame(mydata$MonthlyCharges,mydata$TotalChargesDivTenure)
head(test)

```
```{r}
## Missing value replacement

x=1

while (x <= nrow(mydata))
{
  if ((is.na(mydata$TotalCharges[x])) == TRUE)
    
  { mydata$TotalCharges[x] <- (mydata$MonthlyCharges[x]*mydata$tenure[x])}
  
  x = x + 1
}
```

Check NAs. Now that NAs are gone, we can take a better look at our Total Charges Variable.

```{r}
sum(is.na(mydata$TotalCharges))

```

Let's take a look at our Total Charges:

```{r}
ggplot(mydata, aes(mydata$TotalCharges)) + geom_histogram(binwidth = 20, fill = "#E69F00") + xlab("Total Charges")

```

```{r}
ggplot(mydata, aes(mydata$Churn, mydata$TotalCharges)) + geom_violin(fill = "#FF6677") + xlab("Churn") +ylab("Total Charges") + theme_classic()
```


  >>> Feature Selection

We will now select which features to include into our model. Let's check the column names from the original dataframe "mydata".

* 'customerID' - No inclusion
* 'gender' - No inclusion
* 'SeniorCitizen' - Include
* 'Partner' - No inclusion
* 'Dependents'- No inclusion
* 'tenure' - Include
* 'PhoneService' - No inclusion
* 'MultipleLines' - No inclusion
* 'InternetService' - No inclusion
* 'OnlineSecurity'- No inclusion
* 'OnlineBackup' - No inclusion
* 'DeviceProtection' - No inclusion
* 'TechSupport' - No inclusion
* 'StreamingTV' - No inclusion
* 'StreamingMovies' - No inclusion
* 'Contract' - No inclusion
* 'PaperlessBilling' - No inclusion
* 'PaymentMethod' - No inclusion
* 'MonthlyCharges' - Include
* 'TotalCharges' - Include
* 'Churn' - No inclusion
* 'ChurnLog' - Include
* 'PartnerLog' - Include
* 'DependentsLog' - Include
* 'PaperlessBillingLog' - Include
* 'TotalChargesDivTenure' - No inclusion
 
We will bind these columns with the dataframes we created:
* PaymentFrame2
* TenureFrame2
* ContractFrame2
* Genderframe2
* ServiceFrame2

We will name our data with the selected features: newdata

```{r}
```


```{r}
```


```{r}
head(mydata)
ColVec <- colnames(mydata)
ColVec

newdata <- cbind.data.frame(mydata$SeniorCitizen, mydata$PartnerLog, mydata$DependentsLog, mydata$tenure, Genderframe2, PaymentFrame2, ServiceFrame2, TenureFrame2, mydata$PaperlessBillingLog, ContractFrame2, mydata$MonthlyCharges, mydata$TotalCharges, mydata$ChurnLog)
head(newdata)
```

  >>> Standardizing the Data

This will give the variables zero-mean and unit-variance. This is required for interpretation for a Logistic Regression model.

```{r}


x = 1

while (x<=length(colnames(newdata))) {
  newdata[,x] <- scale(as.numeric(newdata[,x], center = TRUE, scale = TRUE))
  x = x+1
}

newdata$`mydata$ChurnLog` <-mydata$ChurnLog

head(newdata)

```

  
```{r}

bound = 0.5
train = newdata[1:(bound*(nrow(newdata))),]
test = newdata[(((nrow(mydata))*bound)+1):nrow(newdata),]
print("The number of training rows are")
nrow(train)
print("The number of test rows are")
nrow(test)
```
**SECTION 3: MODEL BUILDING**

We will use Logistic Regression as the machine learning model. 

```{r}

model <- glm( as.numeric(`mydata$ChurnLog`) ~.
              ,family=binomial(link='logit'),data=train, control = list(maxit = 200))
```
**SECTION 4: PREDICTION AND ACCURACY EVALUATION**

  >>> Make a prediction

We will now use our test data to make a prediction.

```{r}
predictChurn <- predict(model, newdata = test,type='response')
```

Let's round our prediction up, since we want a 1 or 0 as an output.

```{r}
RoundpredictChurn <- round(predictChurn)
head(RoundpredictChurn)

```

  >>> Measure Accuracy
  
```{r}
conf_mat <- base::table(test$`mydata$ChurnLog`,RoundpredictChurn)
conf_mat

cat("Test accuracy: ", sum(diag(conf_mat))/sum(conf_mat))
```
**SECTION 5: CONCLUSIONS AND FUTURE WORK**

Several other machine learning models could be applied such as K Nearest Neighbour or Descision Trees. A comparison of the accuracy of these models could be provided, and the most accurate model would be selected. Logistic regression was chosen since it plots the data on a curve which fits a Probabilistic curve with two binary outputs. This is reflective of customer churn behaviour.



